name: Scheduled Scraper

on:
  #schedule:
 #    - cron: '*/5 * * * *'  # Every 5 minutes (GitHub only supports 5 min minimum)
 workflow_dispatch:       # Manual run button

jobs:
  run-scraper:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r backend/requirements.txt
          sudo apt-get install -y libnss3  # Needed for Playwright headless
          python -m playwright install

      - name: Run scraper
        run: |
          python backend/scraper/scrape.py

      - name: Commit and push updated tweets.json
        env:
          GH_TOKEN: ${{ secrets.GH_TOKEN }}
        run: |
          git config user.name github-actions
          git config user.email github-actions@github.com
          git remote set-url origin https://x-access-token:${GH_TOKEN}@github.com/0xKimutai/X-AlphaFeed.git
          git add backend/tweets.json
          git commit -m "Update tweets" || echo "No changes to commit"
          git push
